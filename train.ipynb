{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0q3GCJYcPCAj8rNOzq6RX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnavdesai6143/Datathon_TM126/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U4UCEgJ98s7"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "CTG Fetal Distress Classification - Training Script\n",
        "Extracted from main notebook - trains models and saves them\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# Scikit-learn imports\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, StratifiedKFold, cross_validate,\n",
        "    RandomizedSearchCV, GridSearchCV\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    balanced_accuracy_score, f1_score, classification_report,\n",
        "    confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n",
        ")\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Model imports\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Imbalanced-learn imports\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CTG FETAL DISTRESS CLASSIFICATION - MODEL PIPELINE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ============================================================================\n",
        "# SECTION 2: LOAD YOUR CLEANED DATA\n",
        "# ============================================================================\n",
        "cleaned_df = pd.read_csv('ctg_cleaned.csv')\n",
        "X = cleaned_df.drop(columns=['NSP'], errors='ignore')\n",
        "y = cleaned_df['NSP'].astype(int)\n",
        "X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "print(f\"\\nðŸ“Š Dataset Overview:\")\n",
        "print(f\"   Total samples: {len(X)}\")\n",
        "print(f\"   Features: {X.shape[1]}\")\n",
        "print(f\"   Class distribution:\")\n",
        "for cls in sorted(y.unique()):\n",
        "    count = (y == cls).sum()\n",
        "    pct = count / len(y) * 100\n",
        "    print(f\"      Class {cls}: {count} ({pct:.1f}%)\")\n",
        "\n",
        "# ============================================================================\n",
        "# SECTION 3: TRAIN/TEST SPLIT (STRATIFIED)\n",
        "# ============================================================================\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.20\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=TEST_SIZE,\n",
        "    stratify=y,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ“ Train/Test Split: {len(X_train)} train, {len(X_test)} test\")\n",
        "\n",
        "# ============================================================================\n",
        "# SECTION 4: DEFINE MODEL PIPELINES WITH IMBALANCE HANDLING\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BUILDING MODEL PIPELINES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "models = {}\n",
        "\n",
        "models['Logistic_Regression'] = {\n",
        "    'pipeline': ImbPipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('smote', SMOTE(random_state=RANDOM_STATE, k_neighbors=5)),\n",
        "        ('clf', LogisticRegression(\n",
        "            multi_class='multinomial',\n",
        "            solver='lbfgs',\n",
        "            class_weight='balanced',\n",
        "            max_iter=4000,\n",
        "            random_state=RANDOM_STATE\n",
        "        ))\n",
        "    ]),\n",
        "    'param_grid': {\n",
        "        'clf__C': [0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
        "        'clf__penalty': ['l2'],\n",
        "        'smote__k_neighbors': [3, 5, 7]\n",
        "    },\n",
        "    'search_iterations': 15\n",
        "}\n",
        "\n",
        "models['Random_Forest'] = {\n",
        "    'pipeline': ImbPipeline([\n",
        "        ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
        "        ('clf', RandomForestClassifier(\n",
        "            class_weight='balanced_subsample',\n",
        "            random_state=RANDOM_STATE,\n",
        "            n_jobs=-1,\n",
        "            min_samples_leaf=2,\n",
        "            bootstrap=True\n",
        "        ))\n",
        "    ]),\n",
        "    'param_grid': {\n",
        "        'clf__n_estimators': [500, 800, 1000, 1200],\n",
        "        'clf__max_depth': [None, 20, 30, 40],\n",
        "        'clf__min_samples_split': [2, 5, 10],\n",
        "        'clf__min_samples_leaf': [1, 2, 4],\n",
        "        'clf__max_features': ['sqrt', 'log2']\n",
        "    },\n",
        "    'search_iterations': 20\n",
        "}\n",
        "\n",
        "models['Gradient_Boosting'] = {\n",
        "    'pipeline': ImbPipeline([\n",
        "        ('smote', BorderlineSMOTE(random_state=RANDOM_STATE)),\n",
        "        ('clf', GradientBoostingClassifier(\n",
        "            random_state=RANDOM_STATE,\n",
        "            subsample=0.8\n",
        "        ))\n",
        "    ]),\n",
        "    'param_grid': {\n",
        "        'clf__n_estimators': [200, 300, 400, 500],\n",
        "        'clf__learning_rate': [0.01, 0.05, 0.1],\n",
        "        'clf__max_depth': [3, 5, 7],\n",
        "        'clf__min_samples_split': [2, 5, 10],\n",
        "        'clf__subsample': [0.8, 0.9, 1.0]\n",
        "    },\n",
        "    'search_iterations': 20\n",
        "}\n",
        "\n",
        "models['MLP_Neural_Network'] = {\n",
        "    'pipeline': ImbPipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
        "        ('clf', MLPClassifier(\n",
        "            activation='relu',\n",
        "            early_stopping=True,\n",
        "            validation_fraction=0.15,\n",
        "            random_state=RANDOM_STATE,\n",
        "            max_iter=500\n",
        "        ))\n",
        "    ]),\n",
        "    'param_grid': {\n",
        "        'clf__hidden_layer_sizes': [(128, 64), (256, 128, 64), (128, 64, 32), (256, 128)],\n",
        "        'clf__alpha': [1e-5, 1e-4, 1e-3, 1e-2],\n",
        "        'clf__learning_rate_init': [1e-3, 5e-4, 1e-4],\n",
        "        'clf__batch_size': [64, 128, 256]\n",
        "    },\n",
        "    'search_iterations': 18\n",
        "}\n",
        "\n",
        "print(f\"âœ“ Created {len(models)} model pipelines\")\n",
        "\n",
        "# ============================================================================\n",
        "# SECTION 5: HYPERPARAMETER TUNING WITH CROSS-VALIDATION\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING WITH CROSS-VALIDATION & HYPERPARAMETER SEARCH\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "best_estimators = {}\n",
        "\n",
        "for name, model_config in models.items():\n",
        "    print(f\"\\nTraining: {name}\")\n",
        "\n",
        "    search = RandomizedSearchCV(\n",
        "        estimator=model_config['pipeline'],\n",
        "        param_distributions=model_config['param_grid'],\n",
        "        n_iter=model_config['search_iterations'],\n",
        "        scoring='f1_macro',\n",
        "        cv=cv_strategy,\n",
        "        n_jobs=-1,\n",
        "        refit=True,\n",
        "        random_state=RANDOM_STATE,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    search.fit(X_train, y_train)\n",
        "    best_estimators[name] = search.best_estimator_\n",
        "\n",
        "# ============================================================================\n",
        "# SAVE TRAINED MODELS\n",
        "# ============================================================================\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "print(\"\\nðŸ’¾ Saving trained models...\")\n",
        "for name, estimator in best_estimators.items():\n",
        "    model_path = f'models/{name}_model.pkl'\n",
        "    joblib.dump(estimator, model_path)\n",
        "    print(f\"   âœ“ Saved {model_path}\")\n",
        "\n",
        "print(\"\\nâœ“ Training complete! All models saved.\")"
      ]
    }
  ]
}